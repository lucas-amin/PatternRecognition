{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "from keras import applications\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "batch_size = 16\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "data_augmentation = False\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse do dataset e separação entre conjuntos de teste e treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(x_train.shape[1:])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testamos com um modelo de rede neural com 4 convoluções em 2D\n",
    "#### Definimos uma rede neural simples para obter boa comparação com a rede neural profunda, testada a seguir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste do modelo construido manualmente, é possível observar uma acurácia de validação de 63%. Comparando aos resultados proximos de competições, o modelo obteve acurácia baixa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - -10767s -215337us/step - loss: 1.7322 - accuracy: 0.3642 - val_loss: 1.4272 - val_accuracy: 0.4789\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 30s 598us/step - loss: 1.4108 - accuracy: 0.4911 - val_loss: 1.2931 - val_accuracy: 0.5278\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 29s 590us/step - loss: 1.2676 - accuracy: 0.5497 - val_loss: 1.1410 - val_accuracy: 0.6009\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 30s 591us/step - loss: 1.1688 - accuracy: 0.5846 - val_loss: 1.0399 - val_accuracy: 0.6357\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 29s 579us/step - loss: 1.0897 - accuracy: 0.6173 - val_loss: 1.0185 - val_accuracy: 0.6437\n",
      "Fitting duration: -10644.860817670822\n",
      "10000/10000 [==============================] - 1s 135us/step\n",
      "Test loss: 1.0184743337631226\n",
      "Test accuracy: 0.6437000036239624\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          shuffle=True)\n",
    "print(\"Fitting duration: \" + str(time.time() - start_time))\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Com o intuito de identificar o comportamento de redes profundas para o reconhecimento de padrões, testamos uma rede neural residual. O classificador será baseado na rede ResNet50V2, uma rede residual com 50 camadas.\n",
    "#### A rede profunda escolhida foi a ResNet devido a sua capacidade de identificação de atributos globais nas imagens, o que pode facilitar a classificação de objetos com formatos e contextos diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "img_height = img_width = 32\n",
    "\n",
    "# Instanciando o modelo Resnet50V2\n",
    "base_model = applications.resnet_v2.ResNet50V2(weights=None, include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Aplicando pooling e dropout no output\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.7)(x)\n",
    "\n",
    "# Gerando camada de output e instanciando o modelo\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model2 = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "model2.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 366s 7ms/step - loss: 2.3828 - accuracy: 0.2712 - val_loss: 1.7033 - val_accuracy: 0.4109\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 366s 7ms/step - loss: 1.7298 - accuracy: 0.4191 - val_loss: 1.5503 - val_accuracy: 0.4905\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 373s 7ms/step - loss: 1.4785 - accuracy: 0.4972 - val_loss: 1.6820 - val_accuracy: 0.4585\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 384s 8ms/step - loss: 1.3072 - accuracy: 0.5522 - val_loss: 1.2296 - val_accuracy: 0.5829\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 378s 8ms/step - loss: 1.1807 - accuracy: 0.5991 - val_loss: 1.2092 - val_accuracy: 0.6138\n",
      "Fitting duration: 1876.0506908893585\n",
      "10000/10000 [==============================] - 10s 963us/step\n",
      "Test accuracy:0.6137999892234802\n",
      "Loss:1.2092481250762939\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model2.fit(x_train, y_train,\n",
    "      batch_size=batch_size,\n",
    "      epochs=epochs,\n",
    "      validation_data=(x_test, y_test),\n",
    "      shuffle=True)\n",
    "print(\"Fitting duration: \" + str(time.time() - start_time))\n",
    "\n",
    "acc = model2.evaluate(x_test, y_test)\n",
    "print(\"Test accuracy:\" + str(acc[1]))\n",
    "print(\"Loss:\" + str(acc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesmo com um tempo de treinamento muito maior e uma estrutura mais complexa, a rede RESNET obteve resultado muito proximo á rede neural criada anteriormente, isso pode ser explicado por:\n",
    "### A rede RESNET necessita de mais tempo de treinamento, devido a quantidade muito maior de camadas.\n",
    "### Possivelmente essa acurácia melhoraria com mais épocas em seu treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
