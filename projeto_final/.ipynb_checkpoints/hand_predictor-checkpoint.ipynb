{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\lucas\\Anaconda3\\envs\\reconhecimentopadroes\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "from keras import applications\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse do dataset e separação entre conjuntos de teste e treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'evaluation\\\\anno_evaluation.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ac758f656e89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'evaluation'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# load annotations of this set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'anno_%s.pickle'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0manno_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mX_2d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'evaluation\\\\anno_evaluation.pickle'"
     ]
    }
   ],
   "source": [
    "# auxiliary function\n",
    "def depth_two_uint8_to_float(top_bits, bottom_bits):\n",
    "    \"\"\" Converts a RGB-coded depth into float valued depth. \"\"\"\n",
    "    depth_map = (top_bits * 2**8 + bottom_bits).astype('float32')\n",
    "    depth_map /= float(2**16 - 1)\n",
    "    depth_map *= 5.0\n",
    "    return depth_map\n",
    "\n",
    "set = 'evaluation'\n",
    "# load annotations of this set\n",
    "with open(os.path.join(set, 'anno_%s.pickle' % set), 'rb') as fi:\n",
    "    anno_all = pickle.load(fi)\n",
    "X_2d = []\n",
    "X = []\n",
    "y = []\n",
    "NUM_SAMPLES = 5000\n",
    "\n",
    "i = 0\n",
    "\n",
    "items = anno_all.items()\n",
    "img_height = img_width = 320\n",
    "# iterate samples of the set\n",
    "for sample_id, anno in items:\n",
    "    # load data\n",
    "    image = cv2.imread(os.path.join(set, 'color', '%.5d.png' % sample_id))\n",
    "    #image = cv2.resize(image, None, fx = 0.5, fy = 0.5)\n",
    "    image_reshaped = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_reshaped = np.reshape(image_reshaped, (img_height * img_width))\n",
    "    \n",
    "    mask = cv2.imread(os.path.join(set, 'mask', '%.5d.png' % sample_id), cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.normalize(mask, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    #mask = cv2.resize(mask, None, fx = 0.5, fy = 0.5)\n",
    "    mask = np.reshape(mask, (img_height * img_width))\n",
    "\n",
    "    X_2d.append(image)\n",
    "    X.append(image_reshaped)\n",
    "    y.append(mask)\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "    if i >= NUM_SAMPLES:\n",
    "        break\n",
    "\n",
    "\n",
    "X = np.array(X).astype('float32')\n",
    "X_2d = np.array(X_2d).astype('float32')\n",
    "y = np.array(y).astype('float32')\n",
    "\n",
    "print(X.shape)\n",
    "print(X_2d.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando o modelo Resnet50V2\n",
    "base_model = applications.resnet_v2.ResNet50V2(weights=None, include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Aplicando pooling e dropout no output\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.7)(x)\n",
    "\n",
    "batch_size = 16\n",
    "num_classes = 4096\n",
    "epochs = 20\n",
    "data_augmentation = False\n",
    "# Gerando camada de output e instanciando o modelo\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model2 = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.001, decay=1e-5)\n",
    "model2.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "\n",
    "input_shape = img_height * img_width\n",
    "\n",
    "input_img = Input(shape=(input_shape,))\n",
    "encoded = Dense(8192, activation='relu')(input_img)\n",
    "encoded = Dense(1024, activation='relu')(encoded)\n",
    "encoded = Dense(512, activation='relu')(encoded)\n",
    "encoded = Dense(256, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(256, activation='relu')(decoded)\n",
    "encoded = Dense(512, activation='relu')(decoded)\n",
    "decoded = Dense(1024, activation='relu')(decoded)\n",
    "encoded = Dense(8192, activation='relu')(decoded)\n",
    "decoded = Dense(input_shape, activation='sigmoid')(decoded)\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "opt = keras.optimizers.RMSprop(learning_rate=1e-6, decay=1e-6)\n",
    "autoencoder.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(X_train, y_train,\n",
    "                epochs=250,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = autoencoder.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\" + str(acc[1]))\n",
    "print(\"Loss:\" + str(acc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynew = autoencoder.predict(X_train)\n",
    "ynew[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train)):\n",
    "    image = image * 255\n",
    "    image = np.reshape(ynew[i], (img_height, img_width))\n",
    "    image = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    cv2.imwrite(\"./results/image\" + str(i) + \".jpg\", image)\n",
    "    \n",
    "    train_image = np.reshape(y_train[i], (img_height, img_width))\n",
    "    train_image = cv2.normalize(train_image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    \n",
    "    cv2.imshow(\"train\", train_image)\n",
    "    cv2.imshow(\"window\",image)\n",
    "\n",
    "    k = cv2.waitKey(0)\n",
    "    print(k)\n",
    "    if k==98:    # Esc key to stop\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(X_2d, y, test_size=0.2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = img_height * img_width\n",
    "print(num_classes)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train,\n",
    "                epochs=100,\n",
    "                batch_size=8,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = model.evaluate(x_test, y_test)\n",
    "print(\"Test accuracy:\" + str(acc[1]))\n",
    "print(\"Loss:\" + str(acc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
